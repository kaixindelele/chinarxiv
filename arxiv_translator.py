#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Arxivè®ºæ–‡ç¿»è¯‘å™¨ - ä¸»æ¥å£

ä¸»è¦åŠŸèƒ½ï¼š
1. æ•´åˆæ‰€æœ‰ç¿»è¯‘æ­¥éª¤ï¼ˆstep1-step6ï¼‰
2. æä¾›ä¸€ç«™å¼arxivè®ºæ–‡ç¿»è¯‘æœåŠ¡
3. ä»arxivé“¾æ¥åˆ°ç¿»è¯‘PDFçš„å®Œæ•´æµç¨‹
4. æ”¯æŒé…ç½®å‚æ•°å’Œé”™è¯¯å¤„ç†
5. æä¾›ç®€å•æ˜“ç”¨çš„APIæ¥å£

è¾“å…¥ï¼šarxivé“¾æ¥æˆ–ID
è¾“å‡ºï¼šç¿»è¯‘åçš„PDFæ–‡ä»¶

ä½œè€…ï¼šåŸºäºGPT Academicé¡¹ç›®æ”¹è¿›
"""

import os
import sys
import time
import logging
from pathlib import Path
from typing import Tuple, Optional, Dict, Any, List

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# å¯¼å…¥å„ä¸ªæ­¥éª¤çš„æ¨¡å—
try:
    from step1_arxiv_downloader import ArxivDownloader, download_arxiv_paper
    from step2_latex_parser import LaTeXParser, parse_latex_project
    from step3_content_splitter import LaTeXContentSplitter, split_latex_content
    from step6_translation_manager import TranslationManager, translate_latex_segments
    from step5_result_merger import LaTeXResultMerger, merge_translation_result
    from step8_pdf_compiler import TranslationPDFCompiler, compile_translation_to_pdf
    from config import API_KEY, BASE_URL, LLM_MODEL

except ImportError as e:
    print(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰stepæ–‡ä»¶éƒ½åœ¨åŒä¸€ç›®å½•ä¸‹")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ArxivTranslator:
    """
    Arxivè®ºæ–‡ç¿»è¯‘å™¨ä¸»ç±»
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. æ•´åˆå®Œæ•´çš„ç¿»è¯‘æµç¨‹
    2. ç®¡ç†å„ä¸ªæ­¥éª¤çš„åè°ƒ
    3. æä¾›è¿›åº¦åé¦ˆ
    4. å¤„ç†é”™è¯¯å’Œå¼‚å¸¸
    """
    
    def __init__(self, 
                 cache_dir: str = "./arxiv_cache",
                 output_dir: str = "./output", 
                 work_dir: str = "./work",
                 api_key: str = "",
                 base_url: str = "",
                 llm_model: str = "gpt-4o-mini",
                 latex_server_url: str = "http://localhost:9851",
                 max_workers: int = 9,
                 max_token_limit: int = 800,
                 use_cache: bool = True,
                 proxies: dict = None):
        """
        åˆå§‹åŒ–Arxivç¿»è¯‘å™¨
        
        è¾“å…¥ï¼š
        - cache_dir: arxivç¼“å­˜ç›®å½•ï¼Œå¦‚ "./arxiv_cache"
        - output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚ "./output"
        - work_dir: å·¥ä½œç›®å½•ï¼Œå¦‚ "./work"
        - api_key: LLM APIå¯†é’¥
        - base_url: LLM APIåœ°å€
        - llm_model: LLMæ¨¡å‹åç§°ï¼Œå¦‚ "gpt-4o-mini"
        - latex_server_url: LaTeXç¼–è¯‘æœåŠ¡å™¨åœ°å€
        - max_workers: æœ€å¤§å¹¶å‘ç¿»è¯‘çº¿ç¨‹æ•°
        - max_token_limit: æ¯æ®µæœ€å¤§tokené™åˆ¶
        - use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
        - proxies: ä»£ç†é…ç½®
        
        è¾“å‡ºï¼šæ— 
        
        è¿™ä¸ªå‡½æ•°åˆå§‹åŒ–ç¿»è¯‘å™¨ï¼Œè®¾ç½®æ‰€æœ‰å¿…è¦çš„ç»„ä»¶å’Œå‚æ•°
        """
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        self.cache_dir = Path(cache_dir)
        self.output_dir = Path(output_dir) 
        self.work_dir = Path(work_dir)
        
        for dir_path in [self.cache_dir, self.output_dir, self.work_dir]:
            dir_path.mkdir(exist_ok=True)
        
        # ä¿å­˜é…ç½®å‚æ•°
        self.api_key = api_key
        self.base_url = base_url
        self.llm_model = llm_model
        self.latex_server_url = latex_server_url
        self.max_workers = max_workers
        self.max_token_limit = max_token_limit
        self.use_cache = use_cache
        self.proxies = proxies or {}
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.downloader = ArxivDownloader(
            cache_dir=str(self.cache_dir),
            proxies=self.proxies
        )
        
        self.parser = LaTeXParser(
            work_dir=str(self.work_dir)
        )
        
        self.splitter = LaTeXContentSplitter(
            max_token_limit=self.max_token_limit
        )
        
        self.translator = TranslationManager(
            api_key=self.api_key,
            base_url=self.base_url,
            llm_model=self.llm_model,
            max_workers=self.max_workers
        )
        
        self.merger = LaTeXResultMerger()
        
        self.compiler = TranslationPDFCompiler(
            server_url=self.latex_server_url,
            output_dir=str(self.output_dir),
            keep_tex_files=True
        )
        
        # ç¿»è¯‘ç»Ÿè®¡ä¿¡æ¯
        self.translation_stats = {
            'start_time': None,
            'end_time': None,
            'arxiv_id': None,
            'source_path': None,  # æ–°å¢ï¼šä¿å­˜æºç è·¯å¾„
            'total_segments': 0,
            'translated_segments': 0,
            'failed_segments': 0,
            'final_success': False
        }
        
        logger.info(f"Arxivç¿»è¯‘å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"LLMæ¨¡å‹: {self.llm_model}")
        logger.info(f"æœ€å¤§å¹¶å‘: {self.max_workers}")
        logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def translate_arxiv(self, 
                       arxiv_input: str,
                       user_requirements: str = "ä¿æŒå­¦æœ¯æ€§å’Œä¸“ä¸šæ€§ï¼Œç¡®ä¿æœ¯è¯­ç¿»è¯‘çš„ä¸€è‡´æ€§",
                       user_terms: Dict[str, str] = None,
                       progress_callback = None,
                       compile_pdf: bool = True) -> Tuple[bool, str, Dict[str, Any]]:
        """
        ç¿»è¯‘arxivè®ºæ–‡çš„ä¸»å‡½æ•°
        
        è¾“å…¥ï¼š
        - arxiv_input: arxivè¾“å…¥ï¼Œå¦‚ "1812.10695" æˆ– "https://arxiv.org/abs/1812.10695"
        - user_requirements: ç”¨æˆ·ç¿»è¯‘è¦æ±‚ï¼Œå¦‚ "ä¿æŒå­¦æœ¯æ€§"
        - user_terms: ç”¨æˆ·æœ¯è¯­å­—å…¸ï¼Œå¦‚ {"agent": "æ™ºèƒ½ä½“"}
        - progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ (step, progress, message) å‚æ•°
        - compile_pdf: æ˜¯å¦ç¼–è¯‘PDFï¼Œé»˜è®¤True
        
        è¾“å‡ºï¼š
        - success: æ˜¯å¦æˆåŠŸï¼ˆå¸ƒå°”å€¼ï¼‰
        - result: æˆåŠŸæ—¶è¿”å›PDFè·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›é”™è¯¯ä¿¡æ¯ï¼ˆå­—ç¬¦ä¸²ï¼‰
        - details: è¯¦ç»†ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ç»Ÿè®¡å’Œä¸­é—´ç»“æœ
        
        è¿™ä¸ªå‡½æ•°æ˜¯ä¸»è¦çš„å…¬å…±æ¥å£ï¼Œå®Œæˆä»arxivè¾“å…¥åˆ°ç¿»è¯‘PDFçš„å®Œæ•´æµç¨‹
        """
        print("=" * 80)
        print("ğŸš€ å¼€å§‹Arxivè®ºæ–‡ç¿»è¯‘")
        print("=" * 80)
        
        # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
        self.translation_stats['start_time'] = time.time()
        
        details = {
            'arxiv_id': None,
            'source_path': None,
            'merged_latex': None,
            'segments': [],
            'translations': [],
            'merged_content': None,
            'pdf_path': None,
            'errors': []
        }
        
        try:
            # Step 1: ä¸‹è½½Arxivè®ºæ–‡æºç 
            print(f"\nğŸ“¥ Step 1: ä¸‹è½½Arxivè®ºæ–‡æºç ")
            print(f"è¾“å…¥: {arxiv_input}")
            
            if progress_callback:
                progress_callback(1, 10, "æ­£åœ¨ä¸‹è½½Arxivè®ºæ–‡...")
            
            success, extract_path, message = self.downloader.download_and_extract(
                arxiv_input, self.use_cache
            )
            
            if not success:
                error_msg = f"Step 1 å¤±è´¥: {message}"
                details['errors'].append(error_msg)
                print(f"âŒ {error_msg}")
                return False, error_msg, details
            
            details['source_path'] = extract_path
            self.translation_stats['source_path'] = extract_path  # ä¿å­˜æºç è·¯å¾„åˆ°ç»Ÿè®¡ä¿¡æ¯
            
            # æå–arxiv ID
            parsed_success, arxiv_id, _ = self.downloader.parse_arxiv_input(arxiv_input)
            if parsed_success:
                details['arxiv_id'] = arxiv_id
                self.translation_stats['arxiv_id'] = arxiv_id
            
            print(f"âœ… Step 1 å®Œæˆ: {message}")
            print(f"   æºç è·¯å¾„: {extract_path}")
            
            # Step 2: è§£æå’Œåˆå¹¶LaTeXæ–‡ä»¶
            print(f"\nğŸ“ Step 2: è§£æå’Œåˆå¹¶LaTeXæ–‡ä»¶")
            
            if progress_callback:
                progress_callback(2, 20, "æ­£åœ¨è§£æLaTeXæ–‡ä»¶...")
            
            success, merged_content, message = self.parser.parse_and_merge(
                extract_path, add_chinese=True
            )
            
            if not success:
                error_msg = f"Step 2 å¤±è´¥: {message}"
                details['errors'].append(error_msg)
                print(f"âŒ {error_msg}")
                return False, error_msg, details
            
            details['merged_latex'] = merged_content
            print(f"âœ… Step 2 å®Œæˆ: {message}")
            print(f"   åˆå¹¶åæ–‡æ¡£é•¿åº¦: {len(merged_content)} å­—ç¬¦")
            
            # Step 3: æ™ºèƒ½åˆ‡åˆ†å†…å®¹
            print(f"\nâœ‚ï¸ Step 3: æ™ºèƒ½åˆ‡åˆ†å†…å®¹")
            
            if progress_callback:
                progress_callback(3, 30, "æ­£åœ¨åˆ‡åˆ†æ–‡æ¡£å†…å®¹...")
            
            success, segments = split_latex_content(
                merged_content, self.max_token_limit
            )
            
            if not success:
                error_msg = f"Step 3 å¤±è´¥: {segments[0] if segments else 'æœªçŸ¥é”™è¯¯'}"
                details['errors'].append(error_msg)
                print(f"âŒ {error_msg}")
                return False, error_msg, details
            
            details['segments'] = segments
            self.translation_stats['total_segments'] = len(segments)
            
            print(f"âœ… Step 3 å®Œæˆ: åˆ‡åˆ†ä¸º {len(segments)} ä¸ªæ®µè½")
            
            # Step 4: æ‰¹é‡ç¿»è¯‘
            print(f"\nğŸŒ Step 4: æ‰¹é‡ç¿»è¯‘æ–‡æ¡£")
            
            if progress_callback:
                progress_callback(4, 40, f"æ­£åœ¨ç¿»è¯‘ {len(segments)} ä¸ªæ®µè½...")
            
            # å®šä¹‰è¿›åº¦å›è°ƒ
            def translation_progress_callback(current, total):
                if progress_callback:
                    progress = 40 + (current / total) * 40  # 40%-80%
                    progress_callback(4, progress, f"ç¿»è¯‘è¿›åº¦: {current}/{total}")
            
            # è°ƒç”¨ç¿»è¯‘ï¼Œä¼ é€’arxiv_idä»¥æ”¯æŒç¼“å­˜
            success, translations, errors = self.translator.translate_segments(
                segments=segments,
                user_requirements=user_requirements,
                user_terms=user_terms,
                progress_callback=translation_progress_callback,
                arxiv_id=details['arxiv_id']  # ä¼ é€’arxiv_idç”¨äºç¼“å­˜
            )
            
            details['translations'] = translations
            
            if not success:
                error_msg = f"Step 4 å¤±è´¥: ç¿»è¯‘è¿‡ç¨‹å‡ºç°ä¸¥é‡é”™è¯¯"
                details['errors'].extend(errors)
                print(f"âŒ {error_msg}")
                return False, error_msg, details
            
            # ç»Ÿè®¡ç¿»è¯‘ç»“æœ
            successful_translations = sum(1 for i, error in enumerate(errors) if not error)
            failed_translations = len(segments) - successful_translations
            
            self.translation_stats['translated_segments'] = successful_translations
            self.translation_stats['failed_segments'] = failed_translations
            
            print(f"âœ… Step 4 å®Œæˆ: æˆåŠŸç¿»è¯‘ {successful_translations}/{len(segments)} ä¸ªæ®µè½")
            
            if failed_translations > 0:
                print(f"âš ï¸  {failed_translations} ä¸ªæ®µè½ç¿»è¯‘å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸæ–‡")
            
            # Step 5: åˆå¹¶ç¿»è¯‘ç»“æœ
            print(f"\nğŸ”— Step 5: åˆå¹¶ç¿»è¯‘ç»“æœ")

            if progress_callback:
                progress_callback(5, 80, "æ­£åœ¨åˆå¹¶ç¿»è¯‘ç»“æœ...")

            success, merged_content, message = self.merger.merge_translated_segments(
                translated_segments=translations,
                original_segments=segments,
                original_full_content=details['merged_latex'],  # ä¼ é€’å®Œæ•´åŸæ–‡
                llm_model=self.llm_model,
                temperature=0.3
            )
            
            if not success:
                error_msg = f"Step 5 å¤±è´¥: {message}"
                details['errors'].append(error_msg)
                print(f"âŒ {error_msg}")
                return False, error_msg, details
            
            details['merged_content'] = merged_content
            print(f"âœ… Step 5 å®Œæˆ: {message}")
            
            # ä¿å­˜ç¿»è¯‘åçš„texæ–‡ä»¶
            if details['arxiv_id']:
                tex_filename = f"arxiv_{details['arxiv_id']}_translated.tex"
            else:
                tex_filename = f"translated_{time.strftime('%Y%m%d_%H%M%S')}.tex"
            
            tex_path = self.output_dir / tex_filename
            self.merger.save_merged_content(merged_content, str(tex_path))
            print(f"   ç¿»è¯‘åtexæ–‡ä»¶å·²ä¿å­˜: {tex_path}")
            
            # Step 6: ç¼–è¯‘PDFï¼ˆå¯é€‰ï¼‰
            if compile_pdf:
                print(f"\nğŸ“„ Step 6: ç¼–è¯‘PDFæ–‡æ¡£")
                
                if progress_callback:
                    progress_callback(6, 90, "æ­£åœ¨ç¼–è¯‘PDF...")
                
                # å…³é”®ä¿®æ”¹ï¼šä¼ é€’æºç ç›®å½•è·¯å¾„
                success, pdf_result, message = self.compiler.compile_translated_latex(
                    latex_content=merged_content,
                    output_name="translated",
                    arxiv_id=details['arxiv_id'],
                    source_dir=details['source_path']  # ä¼ é€’æºç ç›®å½•ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°ä¾èµ–æ–‡ä»¶
                )
                
                if success:
                    details['pdf_path'] = pdf_result
                    print(f"âœ… Step 6 å®Œæˆ: PDFç¼–è¯‘æˆåŠŸ")
                    print(f"   PDFæ–‡ä»¶è·¯å¾„: {pdf_result}")
                    final_result = pdf_result
                    final_message = f"ç¿»è¯‘å®Œæˆï¼PDFä¿å­˜è‡³: {pdf_result}"
                else:
                    print(f"âš ï¸  Step 6 PDFç¼–è¯‘å¤±è´¥: {pdf_result}")
                    print(f"   ç¿»è¯‘çš„texæ–‡ä»¶ä»å¯ç”¨: {tex_path}")
                    final_result = str(tex_path)
                    final_message = f"ç¿»è¯‘å®Œæˆï¼Œä½†PDFç¼–è¯‘å¤±è´¥ã€‚texæ–‡ä»¶ä¿å­˜è‡³: {tex_path}\nç¼–è¯‘é”™è¯¯: {pdf_result}"
            else:
                print(f"\nâ­ï¸  è·³è¿‡PDFç¼–è¯‘")
                final_result = str(tex_path)
                final_message = f"ç¿»è¯‘å®Œæˆï¼texæ–‡ä»¶ä¿å­˜è‡³: {tex_path}"
            
            # æ›´æ–°æœ€ç»ˆç»Ÿè®¡
            self.translation_stats['end_time'] = time.time()
            self.translation_stats['final_success'] = True
            
            duration = self.translation_stats['end_time'] - self.translation_stats['start_time']
            
            print(f"\nğŸ“Š ç¿»è¯‘ç»Ÿè®¡:")
            print(f"   æ€»è€—æ—¶: {duration:.2f} ç§’")
            print(f"   æˆåŠŸæ®µè½: {self.translation_stats['translated_segments']}")
            print(f"   å¤±è´¥æ®µè½: {self.translation_stats['failed_segments']}")
            print(f"   æºç è·¯å¾„: {self.translation_stats['source_path']}")
            
            if progress_callback:
                progress_callback(6, 100, "ç¿»è¯‘å®Œæˆï¼")
            
            print("=" * 80)
            print("ğŸ‰ Arxivè®ºæ–‡ç¿»è¯‘å®Œæˆ")
            print("=" * 80)
            
            return True, final_result, details
            
        except Exception as e:
            error_msg = f"ç¿»è¯‘è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {e}"
            logger.error(error_msg)
            details['errors'].append(error_msg)
            print(f"âŒ {error_msg}")
            
            self.translation_stats['end_time'] = time.time()
            self.translation_stats['final_success'] = False
            
            import traceback
            traceback.print_exc()
            
            return False, error_msg, details
    
    def get_translation_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¿»è¯‘ç»Ÿè®¡ä¿¡æ¯
        
        è¾“å…¥ï¼šæ— 
        è¾“å‡ºï¼šç»Ÿè®¡ä¿¡æ¯å­—å…¸
        
        è¿™ä¸ªå‡½æ•°è¿”å›è¯¦ç»†çš„ç¿»è¯‘ç»Ÿè®¡ä¿¡æ¯
        """
        stats = self.translation_stats.copy()
        
        if stats['start_time'] and stats['end_time']:
            stats['duration'] = stats['end_time'] - stats['start_time']
            stats['duration_str'] = f"{stats['duration']:.2f} ç§’"
        
        if stats['total_segments'] > 0:
            stats['success_rate'] = f"{(stats['translated_segments']/stats['total_segments']*100):.1f}%"
        else:
            stats['success_rate'] = "0.0%"
        
        return stats

def translate_arxiv_paper(arxiv_input: str,
                         user_requirements: str = "ä¿æŒå­¦æœ¯æ€§å’Œä¸“ä¸šæ€§ï¼Œç¡®ä¿æœ¯è¯­ç¿»è¯‘çš„ä¸€è‡´æ€§",
                         user_terms: Dict[str, str] = None,
                         output_dir: str = "./output",
                         api_key: str = "",
                         base_url: str = "",
                         llm_model: str = "",
                         compile_pdf: bool = True) -> Tuple[bool, str]:
    """
    ä¾¿æ·å‡½æ•°ï¼šç¿»è¯‘arxivè®ºæ–‡ï¼ˆæ”¹è¿›ç‰ˆï¼Œæ”¯æŒä¾èµ–æ–‡ä»¶ï¼‰
    
    è¾“å…¥ï¼š
    - arxiv_input: arxivè¾“å…¥ï¼Œå¦‚ "1812.10695" æˆ–å®Œæ•´URL
    - user_requirements: ç”¨æˆ·ç¿»è¯‘è¦æ±‚
    - user_terms: ç”¨æˆ·æœ¯è¯­å­—å…¸
    - output_dir: è¾“å‡ºç›®å½•
    - api_key: LLM APIå¯†é’¥
    - base_url: LLM APIåœ°å€
    - compile_pdf: æ˜¯å¦ç¼–è¯‘PDF
    
    è¾“å‡ºï¼š
    - success: æ˜¯å¦æˆåŠŸï¼ˆå¸ƒå°”å€¼ï¼‰
    - result: æˆåŠŸæ—¶è¿”å›æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›é”™è¯¯ä¿¡æ¯ï¼ˆå­—ç¬¦ä¸²ï¼‰
    
    è¿™ä¸ªå‡½æ•°æä¾›æœ€ç®€å•çš„è°ƒç”¨æ–¹å¼ï¼Œä¸€æ­¥å®Œæˆarxivè®ºæ–‡ç¿»è¯‘ï¼Œå¹¶ç¡®ä¿ä¾èµ–æ–‡ä»¶æ­£ç¡®å¤„ç†
    """
    try:
        translator = ArxivTranslator(
            output_dir=output_dir,
            api_key=api_key,
            base_url=base_url,
            llm_model=llm_model
        )
        
        success, result, details = translator.translate_arxiv(
            arxiv_input=arxiv_input,
            user_requirements=user_requirements,
            user_terms=user_terms,
            compile_pdf=compile_pdf
        )
        
        if success:
            return True, result
        else:
            return False, f"ç¿»è¯‘å¤±è´¥: {result}"
            
    except Exception as e:
        error_msg = f"ç¿»è¯‘è¿‡ç¨‹å‡ºé”™: {e}"
        logger.error(error_msg)
        return False, error_msg

# æµ‹è¯•å’Œç¤ºä¾‹ä»£ç 
def main():
    """
    ä¸»å‡½æ•°ï¼Œæ¼”ç¤ºArxivç¿»è¯‘å™¨çš„ä½¿ç”¨æ–¹æ³•
    """
    print("=" * 70)
    print("Arxivè®ºæ–‡ç¿»è¯‘å™¨æµ‹è¯•ï¼ˆæ”¹è¿›ç‰ˆï¼‰")
    print("=" * 70)
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "name": "ç»å…¸æœºå™¨å­¦ä¹ è®ºæ–‡",
            "arxiv_id": "1812.10695",
            "description": "GPT-1 åŸå§‹è®ºæ–‡"
        },
        {
            "name": "æœ€æ–°è®ºæ–‡",
            "arxiv_id": "2402.14207", 
            "description": "æœ€æ–°å‘è¡¨è®ºæ–‡"
        }
    ]
    
    print("å¯é€‰æµ‹è¯•ç”¨ä¾‹:")
    for i, case in enumerate(test_cases, 1):
        print(f"  {i}. {case['name']} ({case['arxiv_id']}) - {case['description']}")
    
    # è®©ç”¨æˆ·é€‰æ‹©æµ‹è¯•ç”¨ä¾‹æˆ–è¾“å…¥è‡ªå®šä¹‰ID
    print(f"\nè¯·é€‰æ‹©æµ‹è¯•ç”¨ä¾‹ (1-{len(test_cases)}) æˆ–ç›´æ¥è¾“å…¥arxiv ID:")
    try:
        user_input = input("> ").strip()
        
        if user_input.isdigit() and 1 <= int(user_input) <= len(test_cases):
            selected_case = test_cases[int(user_input) - 1]
            test_arxiv_id = selected_case["arxiv_id"]
            print(f"é€‰æ‹©äº†: {selected_case['name']}")
        else:
            test_arxiv_id = user_input
            print(f"ä½¿ç”¨è‡ªå®šä¹‰è¾“å…¥: {test_arxiv_id}")
            
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•ç”¨ä¾‹")
        test_arxiv_id = test_cases[0]["arxiv_id"]
    except:
        print("è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•ç”¨ä¾‹") 
        test_arxiv_id = test_cases[0]["arxiv_id"]
    
    # # è‡ªå®šä¹‰ç¿»è¯‘è¦æ±‚å’Œæœ¯è¯­
    # user_requirements = "ç¿»è¯‘è¦ä¿æŒå­¦æœ¯æ€§å’Œä¸“ä¸šæ€§ï¼Œç¡®ä¿æœ¯è¯­ç¿»è¯‘çš„ä¸€è‡´æ€§ï¼Œå¯¹äºä¸“ä¸šæœ¯è¯­é¦–æ¬¡å‡ºç°æ—¶ç”¨æ‹¬å·æ ‡æ³¨è‹±æ–‡åŸè¯"
    
    # user_terms = {
    #     "transformer": "å˜æ¢å™¨",
    #     "attention": "æ³¨æ„åŠ›", 
    #     "neural network": "ç¥ç»ç½‘ç»œ",
    #     "machine learning": "æœºå™¨å­¦ä¹ ",
    #     "deep learning": "æ·±åº¦å­¦ä¹ ",
    #     "artificial intelligence": "äººå·¥æ™ºèƒ½"
    # }
    
    # print(f"\nè‡ªå®šä¹‰é…ç½®:")
    # print(f"ç¿»è¯‘è¦æ±‚: {user_requirements}")
    # print(f"æœ¯è¯­è¯å…¸: {len(user_terms)} æ¡")
    
    # # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
    # def progress_callback(step, progress, message):
    #     print(f"Step {step} - {progress:.1f}%: {message}")
    
    # # åˆ›å»ºç¿»è¯‘å™¨
    # print(f"\nåˆ›å»ºArxivç¿»è¯‘å™¨...")
    # translator = ArxivTranslator(
    #     output_dir="./output",
    #     cache_dir="./arxiv_cache",
    #     work_dir="./work"
    # )
    
    # # æ‰§è¡Œç¿»è¯‘
    # print(f"\nå¼€å§‹ç¿»è¯‘ {test_arxiv_id}...")
    # success, result, details = translator.translate_arxiv(
    #     arxiv_input=test_arxiv_id,
    #     user_requirements=user_requirements,
    #     user_terms=user_terms,
    #     progress_callback=progress_callback,
    #     compile_pdf=True  # å°è¯•ç¼–è¯‘PDFï¼Œç°åœ¨åº”è¯¥èƒ½æ‰¾åˆ°ä¾èµ–æ–‡ä»¶äº†
    # )
    
    # # è¾“å‡ºç»“æœ
    # print(f"\n{'='*50}")
    # print("ç¿»è¯‘ç»“æœ")
    # print(f"{'='*50}")
    
    # if success:
    #     print(f"âœ… ç¿»è¯‘æˆåŠŸï¼")
    #     print(f"ç»“æœæ–‡ä»¶: {result}")
        
    #     # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    #     if details['arxiv_id']:
    #         print(f"Arxiv ID: {details['arxiv_id']}")
    #     if details['source_path']:
    #         print(f"æºç è·¯å¾„: {details['source_path']}")
    #     print(f"åˆ‡åˆ†æ®µè½æ•°: {len(details.get('segments', []))}")
    #     print(f"ç¿»è¯‘æ®µè½æ•°: {len(details.get('translations', []))}")
        
    #     # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    #     stats = translator.get_translation_stats()
    #     print(f"\nç¿»è¯‘ç»Ÿè®¡:")
    #     for key, value in stats.items():
    #         if key not in ['start_time', 'end_time']:
    #             print(f"  {key}: {value}")
                
    # else:
    #     print(f"âŒ ç¿»è¯‘å¤±è´¥")
    #     print(f"é”™è¯¯ä¿¡æ¯: {result}")
        
    #     if details['errors']:
    #         print(f"\nè¯¦ç»†é”™è¯¯:")
    #         for error in details['errors']:
    #             print(f"  - {error}")
    
    # æµ‹è¯•ä¾¿æ·å‡½æ•°
    print(f"\n{'='*50}")
    print("æµ‹è¯•ä¾¿æ·å‡½æ•°æ¥å£")
    print(f"{'='*50}")
    
    # åªæµ‹è¯•texç”Ÿæˆï¼Œè·³è¿‡PDFç¼–è¯‘é¿å…é‡å¤
    success, result = translate_arxiv_paper(
        arxiv_input=test_arxiv_id,
        output_dir="./output",
        compile_pdf=True,  # è·³è¿‡PDFç¼–è¯‘ï¼Œé¿å…é‡å¤æµ‹è¯•
        api_key=API_KEY,
        base_url=BASE_URL,
        llm_model=LLM_MODEL
    )
    
    if success:
        print(f"âœ… ä¾¿æ·å‡½æ•°æµ‹è¯•æˆåŠŸ")
        print(f"ç»“æœ: {result}")
    else:
        print(f"âŒ ä¾¿æ·å‡½æ•°æµ‹è¯•å¤±è´¥")
        print(f"é”™è¯¯: {result}")
    
    print(f"\n{'='*70}")
    print("Arxivç¿»è¯‘å™¨æµ‹è¯•å®Œæˆ")
    print(f"{'='*70}")

if __name__ == "__main__":
    main()
